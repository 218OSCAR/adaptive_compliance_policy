{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup all settings here! (Except the plotting codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "root = os.environ.get(\"PIXI_PROJECT_ROOT\", \"\")\n",
    "if root == \"\":\n",
    "    logging.warning(\"PIXI_PROJECT_ROOT environment variable not set. Using default root path '/' which may not be correct.\")\n",
    "\n",
    "sys.path.append(str(Path(root) / \"PyriteML\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"train_multimodal_conv_workspace\"\n",
    "data_path = Path(root) / \"training_outputs\"\n",
    "train_name = \"2026.02.28_19.50.59_cable_mounting_multimodal_conv_230\"\n",
    "ckpt_name = \"epoch=0000-train_loss=0.602\"\n",
    "\n",
    "# By default the kinect data is disabled!\n",
    "workspace_config_overrides = ['kinect=enabled']\n",
    "\n",
    "output_dir = Path(\"ckpt_test_output\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = data_path / train_name / \"checkpoints\" / (ckpt_name + \".ckpt\")\n",
    "if not ckpt_path.exists():\n",
    "    raise FileNotFoundError(f\"Checkpoint not found at {ckpt_path}\")\n",
    "else:\n",
    "    logging.info(f\"Checkpoint found at {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Dict, Callable, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import dill\n",
    "import hydra\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PyriteML.diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "from PyriteML.diffusion_policy.dataset.base_dataset import BaseImageDataset, BaseDataset\n",
    "from PyriteML.diffusion_policy.workspace.train_diffusion_unet_image_workspace import TrainDiffusionUnetImageWorkspace\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "payload = torch.load(open(ckpt_path, 'rb'), map_location='cpu', pickle_module=dill)\n",
    "cfg = payload['cfg']\n",
    "print(\"model_name:\", cfg.policy.obs_encoder._target_)\n",
    "print(\"dataset_path:\", cfg.task.dataset.dataset_path)\n",
    "\n",
    "cls = hydra.utils.get_class(cfg._target_)\n",
    "workspace = cls(cfg)\n",
    "workspace: BaseWorkspace\n",
    "workspace.load_payload(payload, exclude_keys=None, include_keys=None)\n",
    "\n",
    "policy = workspace.model\n",
    "if cfg.training.use_ema:\n",
    "    policy = workspace.ema_model\n",
    "policy.num_inference_steps = cfg.policy.num_inference_steps # DDIM inference iterations\n",
    "\n",
    "policy.eval().to(device)\n",
    "policy.reset()\n",
    "\n",
    "# use normalizer saved in the policy\n",
    "sparse_normalizer = policy.get_normalizer()\n",
    "\n",
    "shape_meta = cfg.task.shape_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in cfg:\n",
    "#     logging.info(f\"{item}: {cfg[item]}\")\n",
    "# for item in cfg.policy:\n",
    "#     logging.info(f\"policy.{item}: {cfg.policy[item]}\")\n",
    "\n",
    "# for item in cfg.policy.obs_encoder:\n",
    "#     logging.info(f\"policy.obs_encoder.{item}: {cfg.policy.obs_encoder[item]}\")\n",
    "\n",
    "# for item in cfg.task:\n",
    "#     logging.info(f\"task.{item}: {cfg.task[item]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the task name here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config_path = Path(\"PyriteML\")/ \"diffusion_policy\" / \"config\" / (task_name + \".yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the dataset used in training\n",
    "# dataset: BaseImageDataset\n",
    "# dataset = hydra.utils.instantiate(cfg.task.dataset)\n",
    "# assert isinstance(dataset, BaseImageDataset) or isinstance(dataset, BaseDataset)\n",
    "# print(\"Test Script: Creating dataloader.\")\n",
    "# train_dataloader = DataLoader(dataset, **cfg.dataloader)\n",
    "# print('train dataset:', len(dataset), 'train dataloader:', len(train_dataloader))\n",
    "\n",
    "# load the dataset specified in config\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "if not task_config_path.exists():\n",
    "    raise FileNotFoundError(f\"Task config not found at {task_config_path}\")\n",
    "\n",
    "with initialize(\n",
    "    version_base=None,\n",
    "    config_path=str(task_config_path.parent),\n",
    "    job_name=\"test_multi_modal_checkpoint\",\n",
    "):\n",
    "    cfg = compose(config_name=task_name, overrides = workspace_config_overrides)\n",
    "    OmegaConf.resolve(cfg)\n",
    "\n",
    "    logging.info(\"Test Script: configuring dataset.\")\n",
    "    dataset: BaseImageDataset\n",
    "    dataset = hydra.utils.instantiate(cfg.task.dataset)\n",
    "    # assert isinstance(dataset, BaseImageDataset) or isinstance(dataset, BaseDataset)\n",
    "    logging.info(\"Test Script: Creating dataloader.\")\n",
    "    train_dataloader = DataLoader(dataset, **cfg.dataloader)\n",
    "    logging.info('train dataset: %d train dataloader: %d', len(dataset), len(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run some tests (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# from einops import rearrange, reduce\n",
    "# import json\n",
    "# from einops import rearrange\n",
    "# def log_action_mse(step_log, category, pred_action, gt_action):\n",
    "#     pred_naction = {\n",
    "#         'sparse': sparse_normalizer['action'].normalize(pred_action['sparse']),\n",
    "#         # 'dense': dense_normalizer['action'].normalize(pred_action['dense'])\n",
    "#     }\n",
    "#     gt_naction = {\n",
    "#         'sparse': sparse_normalizer['action'].normalize(gt_action['sparse']),\n",
    "#         # 'dense': dense_normalizer['action'].normalize(gt_action['dense'])\n",
    "#     }\n",
    "\n",
    "#     B, T, _ = pred_naction['sparse'].shape\n",
    "#     pred_naction_sparse = rearrange(pred_naction['sparse'], 'batch time action_dim -> batch time action_dim')\n",
    "#     gt_naction_sparse = rearrange(gt_naction['sparse'], 'batch time action_dim -> batch time action_dim')\n",
    "#     sparse_loss = F.mse_loss(pred_naction_sparse, gt_naction_sparse, reduction='none')\n",
    "#     sparse_loss = sparse_loss.type(sparse_loss.dtype)\n",
    "#     sparse_loss = reduce(sparse_loss, 'b ... -> b (...)', 'mean')\n",
    "#     sparse_loss = sparse_loss.mean()            \n",
    "\n",
    "#     step_log[f'{category}_sparse_naction_mse_error'] = float(sparse_loss.detach())\n",
    "#     # step_log[f'{category}_sparse_naction_mse_error_pos'] = F.mse_loss(pred_naction_sparse[..., :3], gt_naction_sparse[..., :3])\n",
    "#     # step_log[f'{category}_sparse_naction_mse_error_rot'] = F.mse_loss(pred_naction_sparse[..., 3:9], gt_naction_sparse[..., 3:9])\n",
    "#     # B, T, _, _= pred_naction['dense'].shape\n",
    "#     # pred_naction_dense = pred_naction['dense'].view(B, T, -1, 9)\n",
    "#     # gt_naction_dense = gt_naction['dense'].view(B, T, -1, 9)\n",
    "#     # dense_loss = F.mse_loss(pred_naction_dense, gt_naction_dense, reduction='none')\n",
    "#     # dense_loss = dense_loss.type(dense_loss.dtype)\n",
    "#     # dense_loss = reduce(dense_loss, 'b ... -> b (...)', 'mean')\n",
    "#     # dense_loss = dense_loss.mean()            \n",
    "#     # step_log[f'{category}_dense_naction_mse_error'] = float(dense_loss.detach())\n",
    "#     # step_log[f'{category}_dense_naction_mse_error_pos'] = F.mse_loss(pred_naction_dense[..., :3], gt_naction_dense[..., :3])\n",
    "#     # step_log[f'{category}_dense_naction_mse_error_rot'] = F.mse_loss(pred_naction_dense[..., 3:9], gt_naction_dense[..., 3:9])\n",
    "    \n",
    "# # get a batch of data'\n",
    "# print('get a batch of data')\n",
    "# batch = next(iter(train_dataloader))\n",
    "\n",
    "# # print(batch.keys())\n",
    "# # for key, attr in batch['obs']['sparse'].items():\n",
    "# #     print(\"   obs.sparse.key: \", key, attr.shape)\n",
    "# # for key, attr in batch['obs']['dense'].items():\n",
    "# #     print(\"   obs.dense.key: \", key, attr.shape)\n",
    "# # for key, attr in batch['action'].items():\n",
    "# #     print(\"   action.key: \", key, attr.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's plot something here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the action mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.nn import functional as F\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "def rot6d_to_R(rot6d : torch.Tensor) -> R:\n",
    "    assert rot6d.shape[-1] == 6\n",
    "    a = rot6d[..., :3]\n",
    "    b = rot6d[..., 3:6]\n",
    "    a = F.normalize(a, dim=-1)\n",
    "    b = F.normalize(b - (a * b).sum(dim=-1, keepdim=True) * a, dim=-1)\n",
    "    c = torch.cross(a, b, dim=-1)\n",
    "    R_mat = torch.stack([a, b, c], dim=-2)\n",
    "    return R.from_matrix(R_mat.detach().cpu().numpy())\n",
    "\n",
    "def identity(x : torch.Tensor | np.ndarray) -> np.ndarray:\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()\n",
    "    return x\n",
    "\n",
    "def R_to_euler(R_mat : R) -> np.ndarray:\n",
    "    return R_mat.as_euler('xyz', degrees=True)\n",
    "\n",
    "def cal_R_err(pred : R, gt : R) -> np.ndarray:\n",
    "    R_err = pred.inv() * gt\n",
    "    angle_err = np.rad2deg(R_err.magnitude())\n",
    "    return angle_err\n",
    "\n",
    "def cal_err(pred : np.ndarray, gt : np.ndarray) -> np.ndarray:\n",
    "    return np.linalg.norm(pred - gt, axis=-1)\n",
    "\n",
    "def _ensure_2d(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr[:, None]\n",
    "    return arr\n",
    "\n",
    "def _dim_labels(name: str, d: int):\n",
    "    if d == 3:\n",
    "        # Euler angles or translation\n",
    "        return ['x', 'y', 'z']\n",
    "    elif d == 1:\n",
    "        return ['value']\n",
    "    else:\n",
    "        return [f'dim{i}' for i in range(d)]\n",
    "\n",
    "\n",
    "from typing import Any\n",
    "# Right:  pose9 + vt_pose9 + stiffness1 + grip1 = 20\n",
    "# Left:   pose9 + grip1 = 10\n",
    "# Total = 30\n",
    "\n",
    "action_map : Dict[str, Tuple[Tuple[slice, slice], Callable[[torch.Tensor], Any], Callable[[Any], np.ndarray]]] = {\n",
    "    'trans_left': ((slice(None), slice(0, 3)), identity, identity, cal_err),\n",
    "    'rotation_left': ((slice(None), slice(3, 9)), rot6d_to_R,R_to_euler,  cal_R_err),\n",
    "    'vt_trans_left': ((slice(None), slice(9, 12)), identity, identity, cal_err),\n",
    "    'vt_rotation_left': ((slice(None), slice(12, 18)), rot6d_to_R, R_to_euler, cal_R_err),\n",
    "    'stiffness_left': ((slice(None), slice(18, 19)), identity, identity, cal_err),\n",
    "    'gripper_left': ((slice(None), slice(19, 20)), identity, identity, cal_err),\n",
    "    'trans_right': ((slice(None), slice(20, 23)), identity, identity, cal_err),\n",
    "    'rotation_right': ((slice(None), slice(23, 29)), rot6d_to_R, R_to_euler, cal_R_err),\n",
    "    'gripper_right': ((slice(None), slice(29, 30)), identity, identity, cal_err),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "gt_action = batch['action']\n",
    "pred_action = policy.predict_action(batch['obs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot whatever you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def visualize_sparse_action_comparison(\n",
    "    gt_action_sparse: torch.Tensor,\n",
    "    pred_action_sparse: torch.Tensor,\n",
    "    action_map: Dict[str, Tuple[Tuple[slice, slice], Callable[[torch.Tensor], Any], Callable[[Any], np.ndarray], Callable[[Any, Any], np.ndarray]]],\n",
    "    save_path: Path | str = None,\n",
    "    dpi: int = 180,\n",
    "):\n",
    "    \"\"\"\n",
    "    gt_action_sparse: [T, 30]\n",
    "    pred_action_sparse: [T, 30]\n",
    "    \"\"\"\n",
    "    if isinstance(save_path, Path):\n",
    "        save_path = str(save_path)\n",
    "    assert gt_action_sparse.shape == pred_action_sparse.shape, (\n",
    "        f\"Shape mismatch: gt={gt_action_sparse.shape}, pred={pred_action_sparse.shape}\"\n",
    "    )\n",
    "    assert gt_action_sparse.ndim == 2, (\n",
    "        f\"Expect [T, A], got {gt_action_sparse.shape}\"\n",
    "    )\n",
    "\n",
    "    T, A = gt_action_sparse.shape\n",
    "    time_idx = np.arange(T)\n",
    "\n",
    "    n_items = len(action_map)\n",
    "\n",
    "    groups_per_row = 3\n",
    "    nrows = np.ceil(n_items / groups_per_row).astype(np.int32)\n",
    "    ncols = groups_per_row * 2\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        figsize=(40, 4.2 * nrows),\n",
    "        sharex=True,\n",
    "        constrained_layout=True\n",
    "    )\n",
    "\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    summary = {}\n",
    "\n",
    "    for idx_item, (name, (idx, convert_fn, vis_fn, err_fn)) in enumerate(action_map.items()):\n",
    "        row = idx_item // groups_per_row\n",
    "        group_col = idx_item % groups_per_row\n",
    "\n",
    "        ax_val = axes[row, group_col * 2]\n",
    "        ax_err = axes[row, group_col * 2 + 1]\n",
    "\n",
    "        # raw slices: [T, d_raw]\n",
    "        gt_raw = gt_action_sparse[idx]\n",
    "        pred_raw = pred_action_sparse[idx]\n",
    "\n",
    "        # converted objects\n",
    "        gt_obj = convert_fn(gt_raw)\n",
    "        pred_obj = convert_fn(pred_raw)\n",
    "\n",
    "        # values to visualize\n",
    "        gt_vis = vis_fn(gt_obj)\n",
    "        pred_vis = vis_fn(pred_obj)\n",
    "\n",
    "        is_rotation = (vis_fn is R_to_euler)\n",
    "\n",
    "        if is_rotation:\n",
    "            # gt_vis, pred_vis: [T, 3], in degrees\n",
    "            gt_vis = _ensure_2d(gt_vis)\n",
    "            pred_vis = _ensure_2d(pred_vis)\n",
    "\n",
    "            # rotation error from your function: radians\n",
    "            rot_err = err_fn(pred_obj, gt_obj)   # shape [T]\n",
    "            rot_err = np.asarray(rot_err)\n",
    "\n",
    "            rot_err_plot = rot_err\n",
    "            err_unit = \"deg\"\n",
    "\n",
    "            labels = ['x', 'y', 'z']\n",
    "            for j in range(3):\n",
    "                ax_val.plot(time_idx, gt_vis[:, j], linestyle='-',  label=f'gt_{labels[j]}')\n",
    "                ax_val.plot(time_idx, pred_vis[:, j], linestyle='--', label=f'pred_{labels[j]}')\n",
    "\n",
    "            ax_err.plot(time_idx, rot_err_plot, linewidth=1.8, label='rotation error')\n",
    "\n",
    "            mean_err = float(np.mean(rot_err_plot))\n",
    "            max_err = float(np.max(rot_err_plot))\n",
    "            rmse_err = float(np.sqrt(np.mean(rot_err_plot ** 2)))\n",
    "\n",
    "            summary[name] = {\n",
    "                'type': 'rotation',\n",
    "                'mean_err_deg': mean_err,\n",
    "                'max_err_deg': max_err,\n",
    "                'rmse_err_deg': rmse_err,\n",
    "            }\n",
    "\n",
    "            ax_val.set_title(f'{name} | Euler xyz (deg): pred vs gt')\n",
    "            ax_err.set_title(\n",
    "                f'{name} | geodesic error ({err_unit}) | mean={mean_err:.3f}, max={max_err:.3f}'\n",
    "            )\n",
    "            ax_val.set_ylabel('deg')\n",
    "            ax_err.set_ylabel(err_unit)\n",
    "\n",
    "        else:\n",
    "            # numerical values\n",
    "            gt_vis = _ensure_2d(gt_vis)\n",
    "            pred_vis = _ensure_2d(pred_vis)\n",
    "\n",
    "            d = gt_vis.shape[1]\n",
    "            labels = _dim_labels(name, d)\n",
    "\n",
    "            # 画 pred vs gt\n",
    "            for j in range(d):\n",
    "                ax_val.plot(time_idx, gt_vis[:, j], linestyle='-',  label=f'gt_{labels[j]}')\n",
    "                ax_val.plot(time_idx, pred_vis[:, j], linestyle='--', label=f'pred_{labels[j]}')\n",
    "\n",
    "            # 现在 err_fn 返回的是每个时刻的误差，而不是整体 MSE\n",
    "            # - translation: shape [T], each step = ||pred - gt||_2\n",
    "            # - stiffness/gripper (1D): shape [T], each step = |pred - gt|\n",
    "            err_curve = np.asarray(err_fn(pred_vis, gt_vis)).reshape(-1)\n",
    "\n",
    "            ax_err.plot(time_idx, err_curve, linewidth=1.8, label='error')\n",
    "\n",
    "            mean_err = float(np.mean(err_curve))\n",
    "            max_err = float(np.max(err_curve))\n",
    "            rmse_err = float(np.sqrt(np.mean(err_curve ** 2)))\n",
    "            std_err = float(np.std(err_curve))\n",
    "\n",
    "            summary[name] = {\n",
    "                'type': 'numeric',\n",
    "                'mean_err': mean_err,\n",
    "                'max_err': max_err,\n",
    "                'rmse_err': rmse_err,\n",
    "                'std_err': std_err,\n",
    "            }\n",
    "\n",
    "            ax_val.set_title(f'{name} | pred vs gt')\n",
    "            ax_err.set_title(\n",
    "                f'{name} | error norm | mean={mean_err:.4f}, max={max_err:.4f}, rmse={rmse_err:.4f}'\n",
    "            )\n",
    "            ax_val.set_ylabel('value')\n",
    "            ax_err.set_ylabel('error')\n",
    "\n",
    "        ax_val.grid(True, alpha=0.3)\n",
    "        ax_err.grid(True, alpha=0.3)\n",
    "\n",
    "        ax_val.legend(fontsize=8, ncol=3, loc='best')\n",
    "        ax_err.legend(fontsize=8, ncol=2, loc='best')\n",
    "\n",
    "\n",
    "    total_axes_used = n_items * 2\n",
    "    total_axes = nrows * ncols\n",
    "\n",
    "    for k in range(total_axes_used, total_axes):\n",
    "        r = k // ncols\n",
    "        c = k % ncols\n",
    "        axes[r, c].axis('off')\n",
    "\n",
    "    for c in range(ncols):\n",
    "        axes[-1, c].set_xlabel('timestep')\n",
    "\n",
    "    fig.suptitle('Sparse Action Comparison: Prediction vs Ground Truth', fontsize=16)\n",
    "\n",
    "    if save_path is not None:\n",
    "        fig.savefig(save_path, dpi=dpi, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    return fig, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "gt_action_sparse = gt_action['sparse'][batch_idx]      # expected shape [T, dim_action]\n",
    "pred_action_sparse = pred_action['sparse'][batch_idx]  # expected shape [T, dim_action]\n",
    "\n",
    "fig, summary = visualize_sparse_action_comparison(\n",
    "    gt_action_sparse=gt_action_sparse,\n",
    "    pred_action_sparse=pred_action_sparse,\n",
    "    action_map=action_map,\n",
    "    save_path= output_dir / 'action_comparison.png',\n",
    ")\n",
    "\n",
    "for name, metrics in summary.items():\n",
    "    logging.info(f\"{name}: {metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
